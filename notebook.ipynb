{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enhancing Hospital Efficiency with ML: Data Cleaning, XGBoost, and Predictive Modeling.\n",
    "\n",
    "In the ever-evolving landscape of healthcare, the quest to enhance patient care outcomes and elevate the quality of healthcare services is an ongoing mission. Healthcare organizations are navigating a complex web of challenges, but within these challenges, lies a remarkable opportunity â€“ the power of data.\n",
    "\n",
    "Healthcare analytics is the compass that guides organizations towards this opportunity. It's the art of dissecting and interpreting data, employing both quantitative and qualitative techniques to unveil the hidden gems of insights and patterns within the wealth of healthcare information. Among the multitude of metrics used for performance evaluation, one vital indicator stands out - the Length of Stay (LOS) for patients.\n",
    "\n",
    "Predicting a patient's Length of Stay is akin to holding a key that unlocks a world of possibilities. It empowers hospitals to optimize their treatment plans with precision, a measure that not only reduces LOS but also minimizes infection rates among patients, staff, and visitors. In essence, it's a pathway to not just improving patient care but revolutionizing healthcare management as a whole.\n",
    "\n",
    "In this journey towards better healthcare, you play a pivotal role. You are the data virtuoso, armed with the latest tools and techniques in healthcare analytics. Your mission is to transform raw data into meaningful insights that illuminate the intricate web of patient care. Through the lens of data analysis, you decode the mysteries of patient LOS, revealing trends and patterns that hold the key to more efficient and effective healthcare delivery.\n",
    "\n",
    "Collaborating closely with the healthcare team, you craft compelling data visualizations that bring these insights to life. Your data-driven creations become the guiding stars, steering healthcare professionals towards better decision-making, enhanced care, and safer environments. While the intricacies of your work may often go unnoticed, its impact reverberates throughout the healthcare organization.\n",
    "\n",
    "In the world of healthcare analytics, you are the unsung hero, the one who helps unveil the extraordinary stories of improved patient care and streamlined healthcare management. Your dedication to data and your ability to transform it into illuminating insights contribute to the ongoing saga of healthcare excellence, making every patient's journey towards better health that much more extraordinary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1: Analyzing the train data.\n",
    "\n",
    "Load the train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#--- Read in dataset ----\n",
    "train = pd.read_csv('train.csv')\n",
    "\n",
    "\n",
    "#--- Inspect data ---\n",
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2: Decoding the test data.\n",
    "Load the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(\"./test.csv\")\n",
    "\n",
    "#--- Inspect data ---\n",
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3: Navigating the Missing Values.\n",
    "Calculate the count of null values in each column of the 'train' DataFrame and store the results in a Pandas Series assigned to the variable 'null_values_train'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "null_values_train = train.isnull().sum()\n",
    "\n",
    "#--- Inspect data ---\n",
    "null_values_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 4: Conquering the Enigma of Missing Values.\n",
    "Counting Null Values in test data.\n",
    "\n",
    "Calculate the count of null values in each column of the 'test' DataFrame and store the results in a Pandas Series assigned to the variable 'null_values_test'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "null_values_test = test.isnull().sum()\n",
    "\n",
    "#--- Inspect data ---\n",
    "null_values_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 5: Data Healing\n",
    "Handling Missing Values in train Data.\n",
    "\n",
    "Replace the missing values in the 'Bed Grade' and 'City_Code_Patient' columns of the 'train' DataFrame with their respective modes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Bed Grade'].fillna(train['Bed Grade'].mode()[0], inplace = True)\n",
    "\n",
    "train['City_Code_Patient'].fillna(train['City_Code_Patient'].mode()[0], inplace = True)\n",
    "\n",
    "#--- Inspect data ---\n",
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stp 6: Data Completeness\n",
    "Handling Missing Values in test Data.\n",
    "\n",
    "Replace the missing values in the 'Bed Grade' and 'City_Code_Patient' columns of the 'test' DataFrame with their respective modes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['Bed Grade'].fillna(test['Bed Grade'].mode()[0], inplace = True)\n",
    "\n",
    "test['City_Code_Patient'].fillna(test['City_Code_Patient'].mode()[0], inplace = True)\n",
    "\n",
    "#--- Inspect data ---\n",
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 7: Transforming 'Stay' with LabelEncoder\n",
    "Encoding 'Stay' Column in train Data.\n",
    "\n",
    "You should encode the 'Stay' column in the 'train' DataFrame using LabelEncoder, replacing categorical values with numerical labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "\n",
    "train['Stay'] = le.fit_transform(train['Stay'].astype('str'))\n",
    "#--- Inspect data ---train\n",
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 8: Charting the Unknown\n",
    "Setting a Default Value.\n",
    "\n",
    "The \"Stay\" column, vital for the project, was initially left blank.Task is to assign the value -1 to the 'Stay' column for all rows in the 'test' DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['Stay'] = -1\n",
    "\n",
    "#--- Inspect data ---\n",
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 9: Data Convergence\n",
    "\n",
    "Merging Train and Test Data.\n",
    "\n",
    "Task is to create a new DataFrame named 'df' by concatenating the 'train' and 'test' DataFrames along their rows and resetting the index with continuous numbering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([train, test], ignore_index = True)\n",
    "\n",
    "#--- Inspect data ---\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 10: Transforming Categories into Numbers\n",
    "Categorical Data Label Encoding.\n",
    "\n",
    "Task is to encode the 'Hospital_type_code', 'Hospital_region_code', 'Department', 'Ward_Type', 'Ward_Facility_Code', 'Type of Admission', 'Severity of Illness', and 'Age' columns in the 'df' DataFrame using LabelEncoder, replacing categorical values with numerical labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in ['Hospital_type_code', 'Hospital_region_code', 'Department', 'Ward_Type', 'Ward_Facility_Code', 'Type of Admission', 'Severity of Illness', 'Age']:\n",
    "          le = LabelEncoder()\n",
    "          df[i] = le.fit_transform(df[i].astype('str'))\n",
    "\n",
    "#--- Inspect data ---\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 11: Data Segmentation\n",
    "\n",
    "Filtering the Training Dataset.\n",
    "\n",
    "In this task, you have to create a new DataFrame named 'train' by filtering rows in the DataFrame 'df' where the value in the 'Stay' column is not equal to -1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = df[df['Stay']!=-1]\n",
    "\n",
    "#--- Inspect data ---\n",
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 12: Preparation for Prediction\n",
    "Filtering the Testing Dataset.\n",
    "\n",
    "In this task, you have to create a new DataFrame named 'test' by filtering rows in the DataFrame 'df' where the value in the 'Stay' column is equal to -1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = df[df['Stay']==-1]\n",
    "\n",
    "#--- Inspect data ---\n",
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 13: Feature Engineering for Enhanced Predictive Analysis\n",
    "Column Removal in the Test DataFrame.\n",
    "\n",
    "Task is to create a new DataFrame named 'test1' by dropping the columns 'Stay', 'patientid', 'Hospital_region_code', and 'Ward_Facility_Code' from the 'test' DataFrame.\n",
    "\n",
    "Using this function, group data by different combinations of features such as 'patientid,' 'Hospital_region_code,' and 'Ward_Facility_Code' to calculate counts and then merged these counts back into the datasets for both training and testing data. This process creates new features, such as 'count_id_patient' and 'count_id_patient_hospitalCode,' that reflected the frequency of each combination, offering deeper insights into the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def get_countid_enocde(train, test, cols, name):\n",
    "   temp = train.groupby(cols)['case_id'].count().reset_index().rename(columns = {'case_id': name})\n",
    "   temp2 = test.groupby(cols)['case_id'].count().reset_index().rename(columns = {'case_id': name})\n",
    "   train = pd.merge(train, temp, how='left', on= cols)\n",
    "   test = pd.merge(test,temp2, how='left', on= cols)\n",
    "   train[name] = train[name].astype('float')\n",
    "   test[name] = test[name].astype('float')\n",
    "   train[name].fillna(np.median(temp[name]), inplace = True)\n",
    "   test[name].fillna(np.median(temp2[name]), inplace = True)\n",
    "   return train, test\n",
    "\n",
    "\n",
    "train, test = get_countid_enocde(train, test, ['patientid'], name = 'count_id_patient')\n",
    "train, test = get_countid_enocde(train, test,\n",
    "                                 ['patientid', 'Hospital_region_code'], name = 'count_id_patient_hospitalCode')\n",
    "train, test = get_countid_enocde(train, test,\n",
    "                                 ['patientid', 'Ward_Facility_Code'], name = 'count_id_patient_wardfacilityCode')\n",
    "\n",
    "test1 = test.drop(['Stay', 'patientid', 'Hospital_region_code', 'Ward_Facility_Code'], axis =1)\n",
    "test1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 4: Sculpting the Data\n",
    "Column Removal in the Train DataFrame.\n",
    "\n",
    "Task is to create a new DataFrame named 'train1' by dropping the columns 'case_id', 'patientid', 'Hospital_region_code', and 'Ward_Facility_Code' from the 'train' DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train1 = train.drop(['case_id', 'patientid', 'Hospital_region_code', 'Ward_Facility_Code'], axis=1)\n",
    "\n",
    "# --- Inspect data ---\n",
    "train1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 15: Data Splitting for Model Mastery\n",
    "Splitting Data into Training and Testing.\n",
    "\n",
    "Task is to split the 'train1' data into training and testing sets. Create feature variables X1 by excluding the 'Stay' column and set y1 as the target variable. Split the data into training and testing sets using a 80-20 split ratio, with a random seed of 100 for reproducibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X1 = train1.drop('Stay', axis =1)\n",
    "y1 = train1['Stay']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X1, y1, test_size =0.20, random_state =100)\n",
    "print(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 16: The XGBoost Model Story\n",
    "\n",
    "Training an XGBoost Classifier and Evaluating Accuracy.\n",
    "\n",
    "Task is to create an XGBoost classifier instance named 'classifier_xgb' with specified hyperparameters. Fit the classifier to the training data ('X_train' and 'y_train') and assign it to 'model_xgb'. Use the trained model to make predictions on the test data ('X_test') and store the predictions. Calculate the accuracy of the XGBoost model's predictions and store it in 'acc_score_xgb'. Round the accuracy score to two decimal places."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "classifier_xgb = xgboost.XGBClassifier(max_depth=4, learning_rate=0.1, n_estimators=800,\n",
    "                                  objective='multi:softmax', reg_alpha=0.5, reg_lambda=1.5,\n",
    "                                  booster='gbtree', n_jobs=4, min_child_weight=2, base_score= 0.75)\n",
    "\n",
    "\n",
    "model_xgb = classifier_xgb.fit(X_train, y_train)\n",
    "\n",
    "prediction_xgb = model_xgb.predict(X_test)\n",
    "acc_score_xgb = accuracy_score(prediction_xgb,y_test)\n",
    "\n",
    "acc_score_xgb = round(acc_score_xgb, 2)\n",
    "\n",
    "acc_score_xgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 17: Final Predictive Model Transformation\n",
    "\n",
    "Using the trained XGBoost classifier, make predictions on the \"test1\" dataset. These predictions were based on the features in \"test1\" and stored as \"pred_xgb.\"\n",
    "\n",
    "Task is to use the trained 'classifier_xgb' model to make predictions on the 'test1' DataFrame excluding the 'case_id' column. Store the predictions in 'pred_xgb'. Create a new DataFrame named 'result_xgb' to organize the prediction results with 'pred_xgb' values added to the 'Stay' column. Assign the 'case_id' column from 'test1' to the 'case_id' column in 'result_xgb'. Reorder the columns in 'result_xgb' to have 'case_id' as the first column and 'Stay' as the second column. Replace the numeric labels in the 'Stay' column of 'result_xgb' with provided label_mapping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_mapping = {\n",
    "    0: '0-10', 1: '11-20', 2: '21-30', 3: '31-40', 4: '41-50',\n",
    "    5: '51-60', 6: '61-70', 7: '71-80', 8: '81-90', 9: '91-100',\n",
    "    10: 'More than 100 Days'\n",
    "}\n",
    "\n",
    "pred_xgb = classifier_xgb.predict(test1.iloc[:, 1:])\n",
    "result_xgb = pd.DataFrame(pred_xgb, columns=['Stay'])\n",
    "result_xgb['case_id'] = test1['case_id']\n",
    "result_xgb = result_xgb[['case_id', 'Stay']]\n",
    "result_xgb['Stay'] = result_xgb['Stay'].replace(label_mapping)\n",
    "\n",
    "\n",
    "result_xgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 18: Decoding Patient Stays.\n",
    "\n",
    " Task is to group the 'result_xgb' DataFrame by unique 'Stay' values and calculate the count of unique 'case_id' values in each group. Store the result in the variable 'result'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = result_xgb.groupby('Stay')['case_id'].nunique()\n",
    "\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
